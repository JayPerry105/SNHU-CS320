Jacob Perry 

SNHU CS320 

Project Two 

Project one consisted of three separate areas of functionality. We first created a contact service to all the creation of a contact with a unique ID, first and last name, phone number, and address. Next was the task service, which had a unique task ID, name, and description. Last was the appointment service, which had a unique appointment ID, an appointment date, and a description. All of the features that we implemented in these projects fall into the category of unit testing. My approach to creating these services and the unit tests was heavily, if not entirely, influenced by the software requirements. Every function in the services was written to either satisfy a requirement, or to verify the correctness of a function that was a requirement. An example of this was the function for checking if the firstName or lastName string in the contact class was valid, or less than or equal to ten characters. I know I wrote effective JUnit tests due to running coverage as in the Eclipse IDE. This feature allowed me to see that across all three portions of the project I covered over 87%. This translated to 36 unit tests written and passed. 

The feedback I received from my professor throughout the course helped me to ensure that my code would be technically sound and efficient by the time we submitted Project One. For example, when I first submitted the contact class, I did not check that all necessary strings were tested to be valid input. Another example was the feedback I received which informed me that I had only tested for invalid input for the different services, but not for valid input. I was able to incorporate this feedback into my project, which helped solidify the efficiency of my code. These were just a couple of examples, but I believe that the feedback I received played the biggest role in my end product being both efficient and technically sound. 

The bulk of all software testing techniques in this project were unit tests. Unit testing possesses several distinct characteristics that contribute to its effectiveness and reliability. Unit tests are designed to isolate individual units of code, such as functions or classes, and test their functionality. This isolation allows for more focused testing and helps identify specific issues within the unit. Another characteristic is that unit tests are independent of each other. This ensures that the failure of one test does not impact the results of others. This independence facilitates easier debugging and enhances the overall stability of the testing process. By keeping the scope of the tests small and specific, unit tests aid in pinpointing any sources of failures that may be contained with a set of code. Another goal of unit testing is to achieve a high percentage of overall code coverage to get a comprehensive understanding of all possible issues and bugs that could arise. 

Some popular testing techniques that we did not make use of during this project were integration testing, system testing, and acceptance testing. Integration testing verifies the interaction between each different component in a software application. It occurs after unit testing and involves testing interfaces and compatibility. Integration tests can be conducted incrementally, starting with a few components and gradually expanding to cover the entire system. By uncovering defects related to incompatible interfaces or faulty communication, integration testing contributes to the overall reliability and functionality of the software. An implication of integration testing is that it usually requires all members of the development team to work together effectively and collaboratively. While this may not pose any issue, some dev teams can be fully remote and in different time zones, which could make collaborating in real time a challenge. 

System testing is a comprehensive testing phase that evaluates the entire software system as a whole to ensure that it meets the requirements or standards of a given customer. This type of testing examines the system's behavior and functionality in various scenarios. System testing is made up of multiple aspects, including functional testing, performance testing, security testing, and usability testing. It verifies whether the system meets functional requirements, performs well under expected workloads, remains secure against potential vulnerabilities, and offers a user-friendly experience. System testing is typically conducted in an environment that closely resembles the production environment to simulate real world conditions. By validating the system's functionality and performance as a whole, system testing helps to ensure the reliability and quality of the software for deployment. An implication of system testing is that sometimes mimicing a production environment can be resource heavy. It can involve anything from configuring necessary software, hardware, and even network infrastructure. 

Acceptance testing in software development involves verifying whether a system meets specified requirements and user expectations. It typically involves end-users or stakeholders executing test cases to ensure the system's compliance with their needs. Acceptance testing helps validate the system's functionality, usability, and suitability for deployment. However, there are potential drawbacks to acceptance testing. It can be time consuming and requires significant effort to create comprehensive test scenarios. There may also be challenges in properly involving and coordinating with end-users or stakeholders. With all of this being said, acceptance testing alone may not fully uncover every defect, along with having to rely on user input at times. Efficient planning is a key factor in successful acceptance testing. 

Throughout this project it became apparent that you had to think with a test driven mindset. If I noticed that I had written a portion of code that I knew had not yet had a test written for it, I knew that portion was going to require more unit tests to be written. Knowing that if I added more functionality to either the classes or services I coded throughout this course felt less cumbersome due to the fact that I would be responsible for creating the test cases for them. In my experience in this project, I had to employ the most caution when verifying that none of my unit tests affected one another. For example, I initially wrote some unit tests to call upon the same variable which was of type integer. This did not work due to the fact that the tests were not guaranteed to run in the order of which they were written. I counteracted this by instead referring to the size-1 in this specific case, which removed the dependencies from one test to another.  

I did my best to eliminate any bias by simply imagining that it was not my code that I was writing tests for. Although a bias on a project such as this could be rather trivial, that does not mean it could not exist. One way that bias could play a part in testing your own code would be catering test cases to fit the way that you initially coded something. If something did not make perfect sense from a logic standpoint, but had a test written for it that was misaligned in the same way, and outside point of view might see that bias clear as day. 

Being disciplined in one's commitment to quality as a software developer is crucial. Cutting corners in writing or testing code can lead to instability, poor maintainability, and compromised user trust. To avoid technical debt, developers should do their best to follow best practices, engage in code reviews, and prioritize documentation and knowledge sharing. Another way to avoid technical debt as a developer is to prioritize regular code refactoring, which involves improving code structure and readability without altering its functionality. Upholding quality standards ensures long-term stability and a solid reputation. By prioritizing code quality, conducting thorough testing, and seeking feedback, software developers can deliver reliable and maintainable software solutions. 

 
